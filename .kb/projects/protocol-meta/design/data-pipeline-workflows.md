# ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì›Œí¬í”Œë¡œìš°

## ê°œìš”
SpreadsheetExpertë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ê¸°íš-ê°œë°œ ê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì˜ ì™„ì „ ìë™í™” ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

## í•µì‹¬ ì•„í‚¤í…ì²˜

### ğŸ—ï¸ ë°ì´í„° í”Œë¡œìš° êµ¬ì¡°
```
ê¸°íšì (ì—‘ì…€/êµ¬ê¸€ì‹œíŠ¸) â†’ SpreadsheetExpert â†’ ì–¸ì–´ ì „ë¬¸ê°€ â†’ ê²Œì„/ì•±
                                    â†“
                                DB ì „ë¬¸ê°€ â†’ ë°ì´í„°ë² ì´ìŠ¤
```

### ğŸ¯ ì—­í• ë³„ ì±…ì„ ë¶„ë¦¬

#### SpreadsheetExpert (ë°ì´í„° ì†ŒìŠ¤ í—ˆë¸Œ)
- **ì…ë ¥**: ì—‘ì…€ íŒŒì¼, êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸
- **ì¶œë ¥**: JSON, CSV, YAML ë“± êµ¬ì¡°í™”ëœ ë°ì´í„°
- **ì—­í• **: ë°ì´í„° ê²€ì¦, ë³€í™˜, í’ˆì§ˆ ê´€ë¦¬

#### ì–¸ì–´ ì „ë¬¸ê°€ (êµ¬í˜„ ë‹´ë‹¹)
- **ì…ë ¥**: SpreadsheetExpertì˜ ë³€í™˜ëœ ë°ì´í„°
- **ì¶œë ¥**: ëŸ°íƒ€ì„ ì½”ë“œ, ë°ì´í„° ë¡œë”, êµ¬ì¡°ì²´/í´ë˜ìŠ¤
- **ì—­í• **: í”Œë«í¼ë³„ ë°ì´í„° í™œìš© ì½”ë“œ ìƒì„±

#### DB ì „ë¬¸ê°€ (ì €ì¥ì†Œ ê´€ë¦¬)
- **ì…ë ¥**: SpreadsheetExpertì˜ êµ¬ì¡°í™”ëœ ë°ì´í„°
- **ì¶œë ¥**: DDL, ë§ˆì´ê·¸ë ˆì´ì…˜, ìµœì í™”ëœ ì¿¼ë¦¬
- **ì—­í• **: ë°ì´í„° ì˜ì†ì„± ë° ì„±ëŠ¥ ìµœì í™”

## ì‹¤ì œ ì›Œí¬í”Œë¡œìš° ì‹œë‚˜ë¦¬ì˜¤

### ğŸ® ì‹œë‚˜ë¦¬ì˜¤ 1: ê²Œì„ ì•„ì´í…œ ë°ì´í„° ì—…ë°ì´íŠ¸

#### ìƒí™©
ê¸°íšìê°€ ìƒˆë¡œìš´ ë¬´ê¸° ì•„ì´í…œì„ ì¶”ê°€í•˜ê³  ê¸°ì¡´ ì•„ì´í…œì˜ ë°¸ëŸ°ìŠ¤ë¥¼ ìˆ˜ì •

#### ì›Œí¬í”Œë¡œìš°
```mermaid
graph TD
    A[ê¸°íšì: ì•„ì´í…œ ì‹œíŠ¸ ìˆ˜ì •] --> B[SpreadsheetExpert ê°ì§€]
    B --> C[ë°ì´í„° ê²€ì¦ ë° ë³€í™˜]
    C --> D{í”„ë¡œì íŠ¸ íƒ€ì…}
    
    D -->|Unity| E[UnityExpert í˜¸ì¶œ]
    D -->|Unreal| F[UnrealExpert í˜¸ì¶œ]
    D -->|ì›¹ê²Œì„| G[TypeScriptExpert í˜¸ì¶œ]
    
    E --> H[ScriptableObject ì—…ë°ì´íŠ¸]
    F --> I[DataTable ì—…ë°ì´íŠ¸]
    G --> J[JSON ë¡œë” ì—…ë°ì´íŠ¸]
    
    C --> K[SQLiteExpert í˜¸ì¶œ]
    K --> L[ê²Œì„ DB í…Œì´ë¸” ì—…ë°ì´íŠ¸]
    
    H --> M[Unity ë¹Œë“œ í…ŒìŠ¤íŠ¸]
    I --> N[Unreal ì»´íŒŒì¼ í…ŒìŠ¤íŠ¸]
    J --> O[ì›¹ ì•± ë°°í¬]
    L --> P[DB ë§ˆì´ê·¸ë ˆì´ì…˜]
```

#### êµ¬ì²´ì  ë‹¨ê³„

**1ë‹¨ê³„: ë³€ê²½ ê°ì§€ ë° ê²€ì¦ (SpreadsheetExpert)**
```python
# ìë™ ì‹¤í–‰ë˜ëŠ” í”„ë¡œì„¸ìŠ¤
def on_spreadsheet_change(file_path: str):
    # 1. ë³€ê²½ëœ ì‹œíŠ¸ ë¡œë“œ
    processor = ExcelProcessor(file_path)
    sheets = processor.load_excel()
    
    # 2. ë°ì´í„° ê²€ì¦
    validation_rules = GAME_ITEM_RULES
    errors = processor.validate_data("Items", validation_rules)
    
    if errors:
        # ê¸°íšìì—ê²Œ ì—ëŸ¬ ë¦¬í¬íŠ¸ ì „ì†¡
        send_error_report(errors)
        return
    
    # 3. ë°ì´í„° ë³€í™˜
    game_processor = GameDataProcessor(processor)
    item_data = game_processor.process_item_data()
    
    # 4. ë‹¤ìŒ ë‹¨ê³„ íŠ¸ë¦¬ê±°
    trigger_language_experts(item_data)
    trigger_db_experts(item_data)
```

**2ë‹¨ê³„: í”Œë«í¼ë³„ ì½”ë“œ ìƒì„± (ì–¸ì–´ ì „ë¬¸ê°€)**

**Unity (UnityExpert)**
```csharp
// ìë™ ìƒì„±ë˜ëŠ” C# ì½”ë“œ
[System.Serializable]
public class ItemDatabase : MonoBehaviour
{
    [SerializeField] private List<ItemData> items;
    
    public void LoadFromJson(string jsonPath)
    {
        string jsonContent = File.ReadAllText(jsonPath);
        var itemContainer = JsonUtility.FromJson<ItemContainer>(jsonContent);
        items = itemContainer.items;
        Debug.Log($"ì•„ì´í…œ {items.Count}ê°œ ë¡œë“œ ì™„ë£Œ");
    }
    
    public ItemData GetItem(string itemId)
    {
        return items.Find(item => item.id == itemId);
    }
}
```

**TypeScript (TypeScriptExpert)**
```typescript
// ìë™ ìƒì„±ë˜ëŠ” TypeScript ì½”ë“œ
interface ItemData {
  id: string;
  name: string;
  type: ItemType;
  stats: ItemStats;
  price: PriceData;
}

class ItemManager {
  private items: Map<string, ItemData> = new Map();
  
  async loadItems(dataUrl: string): Promise<void> {
    try {
      const response = await fetch(dataUrl);
      const data = await response.json();
      
      for (const [id, item] of Object.entries(data.items)) {
        this.items.set(id, item as ItemData);
      }
      
      console.log(`ì•„ì´í…œ ${this.items.size}ê°œ ë¡œë“œ ì™„ë£Œ`);
    } catch (error) {
      console.error('ì•„ì´í…œ ë¡œë“œ ì‹¤íŒ¨:', error);
    }
  }
  
  getItem(itemId: string): ItemData | undefined {
    return this.items.get(itemId);
  }
}
```

**3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ (DB ì „ë¬¸ê°€)**

**SQLite (SQLiteExpert)**
```sql
-- ìë™ ìƒì„±ë˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜
BEGIN TRANSACTION;

-- ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€ (ê¸°íšìê°€ ì¶”ê°€í•œ í•„ë“œ)
ALTER TABLE items ADD COLUMN durability INTEGER DEFAULT 100;
ALTER TABLE items ADD COLUMN enchant_level INTEGER DEFAULT 0;

-- ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë°¸ëŸ°ìŠ¤ ì¡°ì •)
UPDATE items SET attack_power = attack_power * 1.1 WHERE item_type = 'weapon';
UPDATE items SET price = ROUND(price * 0.95) WHERE rarity = 'common';

-- ìƒˆ ì•„ì´í…œ ì¶”ê°€
INSERT INTO items (id, name, type, rarity, attack_power, price, durability) VALUES
('sword_legendary_001', 'Excalibur', 'weapon', 'legendary', 250, 10000, 200),
('shield_epic_001', 'Dragon Shield', 'armor', 'epic', 0, 5000, 150);

COMMIT;
```

### ğŸŒ ì‹œë‚˜ë¦¬ì˜¤ 2: ë‹¤êµ­ì–´ ì§€ì› ì‹œìŠ¤í…œ

#### ìƒí™©
ìƒˆë¡œìš´ ì–¸ì–´(ì¼ë³¸ì–´) ì¶”ê°€ ë° ê¸°ì¡´ í…ìŠ¤íŠ¸ ìˆ˜ì •

#### ì›Œí¬í”Œë¡œìš°

**1ë‹¨ê³„: ë¡œì»¬ë¼ì´ì œì´ì…˜ ì‹œíŠ¸ ì²˜ë¦¬**
```python
def process_localization_update():
    # êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ìµœì‹  ë²ˆì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sheets_processor = GoogleSheetsProcessor('credentials.json')
    df = sheets_processor.load_sheet(LOCALIZATION_SHEET_ID, 'Translations')
    
    # ë‹¤êµ­ì–´ ë°ì´í„° êµ¬ì¡°í™”
    localization_data = process_localization_data(df)
    
    # ê° ì–¸ì–´ë³„ íŒŒì¼ ìƒì„±
    for language, texts in localization_data['localization'].items():
        output_path = f"Assets/Localization/{language}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(texts, f, ensure_ascii=False, indent=2)
    
    # ì–¸ì–´ ì „ë¬¸ê°€ë“¤ì—ê²Œ ì•Œë¦¼
    notify_language_experts(localization_data)
```

**2ë‹¨ê³„: í”Œë«í¼ë³„ ë¡œì»¬ë¼ì´ì œì´ì…˜ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸**

**Unity (UnityExpert)**
```csharp
public class LocalizationManager : MonoBehaviour
{
    [SerializeField] private SystemLanguage currentLanguage;
    private Dictionary<string, string> localizedTexts = new Dictionary<string, string>();
    
    void Start()
    {
        LoadLocalization(Application.systemLanguage);
    }
    
    public void LoadLocalization(SystemLanguage language)
    {
        string languageCode = GetLanguageCode(language);
        string path = Path.Combine(Application.streamingAssetsPath, $"Localization/{languageCode}.json");
        
        if (File.Exists(path))
        {
            string jsonContent = File.ReadAllText(path, Encoding.UTF8);
            var localizationData = JsonUtility.FromJson<LocalizationData>(jsonContent);
            
            localizedTexts.Clear();
            foreach (var item in localizationData.texts)
            {
                localizedTexts[item.key] = item.value;
            }
            
            currentLanguage = language;
            UpdateAllLocalizedTexts();
        }
    }
    
    public string GetLocalizedText(string key)
    {
        return localizedTexts.TryGetValue(key, out string value) ? value : $"[MISSING: {key}]";
    }
}
```

### ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹¤ì‹œê°„ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ

#### ìƒí™©
ê²Œì„ì´ ë¼ì´ë¸Œ ì¤‘ì¸ ìƒíƒœì—ì„œ ê¸´ê¸‰ ë°¸ëŸ°ìŠ¤ íŒ¨ì¹˜ í•„ìš”

#### ì›Œí¬í”Œë¡œìš°

**1ë‹¨ê³„: í•«í”½ìŠ¤ ë°ì´í„° ì¤€ë¹„**
```python
class HotfixPipeline:
    def __init__(self):
        self.validator = DataQualityManager()
        self.sync_server = DataSyncServer()
    
    def process_hotfix(self, sheet_id: str, worksheet: str):
        # 1. ë³€ê²½ëœ ë°ì´í„° ê°ì§€
        processor = GoogleSheetsProcessor('hotfix_credentials.json')
        df = processor.load_sheet(sheet_id, worksheet)
        
        # 2. ì—„ê²©í•œ ê²€ì¦ (ë¼ì´ë¸Œ í™˜ê²½)
        errors = self.validator.check_data_quality(df, 'hotfix_data')
        if errors['quality_score'] < 95:
            raise ValueError("í•«í”½ìŠ¤ ë°ì´í„° í’ˆì§ˆì´ ê¸°ì¤€ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤.")
        
        # 3. ì•ˆì „í•œ ë³€í™˜
        game_processor = GameDataProcessor(processor)
        hotfix_data = game_processor.process_skill_data()
        
        # 4. ìŠ¤í…Œì´ì§• í™˜ê²½ í…ŒìŠ¤íŠ¸
        if not self.test_in_staging(hotfix_data):
            raise ValueError("ìŠ¤í…Œì´ì§• í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
        # 5. ë¼ì´ë¸Œ ë°°í¬
        self.deploy_to_live(hotfix_data)
        
        # 6. ì‹¤ì‹œê°„ í´ë¼ì´ì–¸íŠ¸ ì•Œë¦¼
        asyncio.create_task(
            self.sync_server.broadcast_update({
                'type': 'hotfix',
                'data': hotfix_data,
                'timestamp': datetime.now().isoformat()
            })
        )
```

**2ë‹¨ê³„: í´ë¼ì´ì–¸íŠ¸ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**

**Node.js (NodeJSExpert)**
```javascript
// ì„œë²„ ì‚¬ì´ë“œ í•«í”½ìŠ¤ ë°°í¬
class HotfixDeployment {
    constructor() {
        this.redisClient = redis.createClient();
        this.wsServer = new WebSocketServer({ port: 8080 });
    }
    
    async deployHotfix(hotfixData) {
        try {
            // Redisì— í•«í”½ìŠ¤ ë°ì´í„° ì €ì¥
            await this.redisClient.setex(
                'game_data:hotfix', 
                3600, 
                JSON.stringify(hotfixData)
            );
            
            // ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì•Œë¦¼
            const message = {
                type: 'data_update',
                category: 'hotfix',
                data: hotfixData,
                timestamp: new Date().toISOString()
            };
            
            this.wsServer.clients.forEach(client => {
                if (client.readyState === WebSocket.OPEN) {
                    client.send(JSON.stringify(message));
                }
            });
            
            console.log('í•«í”½ìŠ¤ ë°°í¬ ì™„ë£Œ:', hotfixData.version);
            
        } catch (error) {
            console.error('í•«í”½ìŠ¤ ë°°í¬ ì‹¤íŒ¨:', error);
            throw error;
        }
    }
}
```

## ê³ ê¸‰ ìë™í™” ê¸°ëŠ¥

### ğŸ”„ ì§€ëŠ¥í˜• ì¶©ëŒ í•´ê²°

#### ë™ì‹œ í¸ì§‘ ì¶©ëŒ ì²˜ë¦¬
```python
class ConflictResolver:
    def __init__(self):
        self.version_control = VersionControl()
    
    def resolve_concurrent_edits(self, changes_a: Dict, changes_b: Dict) -> Dict:
        """ë‘ ì‚¬ìš©ìì˜ ë™ì‹œ í¸ì§‘ ì¶©ëŒ í•´ê²°"""
        
        # 1. ë³€ê²½ ì‚¬í•­ ë¶„ì„
        conflicts = self.find_conflicts(changes_a, changes_b)
        
        # 2. ìë™ í•´ê²° ê°€ëŠ¥í•œ ì¶©ëŒ ì²˜ë¦¬
        auto_resolved = []
        manual_required = []
        
        for conflict in conflicts:
            if conflict['type'] == 'non_overlapping':
                # ì„œë¡œ ë‹¤ë¥¸ í•„ë“œ ìˆ˜ì • -> ìë™ ë³‘í•©
                auto_resolved.append(conflict)
            elif conflict['type'] == 'additive':
                # ë‘˜ ë‹¤ ìƒˆ í–‰ ì¶”ê°€ -> ìë™ ë³‘í•©
                auto_resolved.append(conflict)
            else:
                # ê°™ì€ í•„ë“œ ë‹¤ë¥¸ ê°’ -> ìˆ˜ë™ í•´ê²° í•„ìš”
                manual_required.append(conflict)
        
        # 3. ë³‘í•©ëœ ê²°ê³¼ ìƒì„±
        merged_result = self.merge_changes(changes_a, changes_b, auto_resolved)
        
        if manual_required:
            # ê¸°íšìì—ê²Œ ìˆ˜ë™ í•´ê²° ìš”ì²­
            self.request_manual_resolution(manual_required)
            return None
        
        return merged_result
```

### ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

#### ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì¶”ì 
```python
class PipelineMonitor:
    def __init__(self):
        self.metrics = defaultdict(list)
        self.alerts = AlertManager()
    
    def track_performance(self, stage: str, duration: float, data_size: int):
        """ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ì¸¡ì •"""
        metric = {
            'timestamp': datetime.now(),
            'stage': stage,
            'duration': duration,
            'data_size': data_size,
            'throughput': data_size / duration
        }
        
        self.metrics[stage].append(metric)
        
        # ì„±ëŠ¥ ì„ê³„ê°’ í™•ì¸
        if duration > self.get_threshold(stage):
            self.alerts.send_performance_warning(stage, duration)
    
    def get_optimization_suggestions(self) -> List[str]:
        """ì„±ëŠ¥ ìµœì í™” ì œì•ˆ"""
        suggestions = []
        
        for stage, metrics in self.metrics.items():
            recent_metrics = metrics[-10:]  # ìµœê·¼ 10ê°œ
            avg_duration = sum(m['duration'] for m in recent_metrics) / len(recent_metrics)
            
            if stage == 'excel_processing' and avg_duration > 5.0:
                suggestions.append("ëŒ€ìš©ëŸ‰ ì—‘ì…€ íŒŒì¼ì— ëŒ€í•´ ì²­í¬ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™” ê¶Œì¥")
            
            elif stage == 'data_validation' and avg_duration > 2.0:
                suggestions.append("ë°ì´í„° ê²€ì¦ ê·œì¹™ ìµœì í™” ë˜ëŠ” ë³‘ë ¬ ì²˜ë¦¬ ë„ì… ê¶Œì¥")
            
            elif stage == 'code_generation' and avg_duration > 10.0:
                suggestions.append("ì½”ë“œ í…œí”Œë¦¿ ìºì‹± ë˜ëŠ” ì¦ë¶„ ìƒì„± ë°©ì‹ ë„ì… ê¶Œì¥")
        
        return suggestions
```

### ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ

#### ë°ì´í„° êµ¬ì¡° ìµœì í™” ì œì•ˆ
```python
class SmartRecommendation:
    def __init__(self):
        self.analyzer = DataStructureAnalyzer()
    
    def analyze_spreadsheet_structure(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ êµ¬ì¡° ë¶„ì„ ë° ê°œì„  ì œì•ˆ"""
        
        analysis = {
            'data_types': self.analyzer.analyze_data_types(df),
            'relationships': self.analyzer.find_relationships(df),
            'normalization': self.analyzer.check_normalization(df),
            'performance': self.analyzer.estimate_performance(df)
        }
        
        recommendations = []
        
        # 1. ë°ì´í„° íƒ€ì… ìµœì í™”
        for col, dtype_info in analysis['data_types'].items():
            if dtype_info['recommended'] != dtype_info['current']:
                recommendations.append({
                    'type': 'data_type_optimization',
                    'column': col,
                    'current': dtype_info['current'],
                    'recommended': dtype_info['recommended'],
                    'benefit': dtype_info['memory_saving']
                })
        
        # 2. ì •ê·œí™” ì œì•ˆ
        if analysis['normalization']['score'] < 0.7:
            recommendations.append({
                'type': 'normalization',
                'current_score': analysis['normalization']['score'],
                'suggestions': analysis['normalization']['suggestions']
            })
        
        # 3. ì¸ë±ì‹± ì œì•ˆ
        for col in analysis['performance']['index_candidates']:
            recommendations.append({
                'type': 'indexing',
                'column': col,
                'reason': 'ìì£¼ ê²€ìƒ‰ë˜ëŠ” ì»¬ëŸ¼',
                'expected_improvement': '50-80% ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ'
            })
        
        return {
            'analysis': analysis,
            'recommendations': recommendations,
            'priority_score': self.calculate_priority_score(recommendations)
        }
```

## í’ˆì§ˆ ë³´ì¦ ë° í…ŒìŠ¤íŒ…

### ğŸ§ª ìë™ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ

#### ë°ì´í„° í’ˆì§ˆ í…ŒìŠ¤íŠ¸
```python
class DataQualityTests:
    def __init__(self):
        self.test_suite = TestSuite()
    
    def run_quality_tests(self, data: Dict) -> TestResult:
        """í¬ê´„ì ì¸ ë°ì´í„° í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        results = TestResult()
        
        # 1. ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± í…ŒìŠ¤íŠ¸
        schema_result = self.test_schema_compliance(data)
        results.add('schema_compliance', schema_result)
        
        # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë£° í…ŒìŠ¤íŠ¸
        business_result = self.test_business_rules(data)
        results.add('business_rules', business_result)
        
        # 3. ì°¸ì¡° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸
        integrity_result = self.test_referential_integrity(data)
        results.add('referential_integrity', integrity_result)
        
        # 4. ì„±ëŠ¥ ì„íŒ©íŠ¸ í…ŒìŠ¤íŠ¸
        performance_result = self.test_performance_impact(data)
        results.add('performance_impact', performance_result)
        
        # 5. ë³´ì•ˆ ì·¨ì•½ì  í…ŒìŠ¤íŠ¸
        security_result = self.test_security_vulnerabilities(data)
        results.add('security', security_result)
        
        return results
    
    def test_business_rules(self, data: Dict) -> TestResult:
        """ê²Œì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦"""
        errors = []
        
        # ì•„ì´í…œ ê°€ê²© í•©ë¦¬ì„± ê²€ì‚¬
        for item_id, item in data.get('items', {}).items():
            if item['type'] == 'weapon' and item['price']['buy'] < item['stats']['attack'] * 10:
                errors.append(f"ë¬´ê¸° {item_id}ì˜ ê°€ê²©ì´ ê³µê²©ë ¥ ëŒ€ë¹„ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤.")
            
            if item['rarity'] == 'legendary' and item['price']['buy'] < 1000:
                errors.append(f"ì „ì„¤ ì•„ì´í…œ {item_id}ì˜ ê°€ê²©ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤.")
        
        return TestResult(success=len(errors) == 0, errors=errors)
```

## í˜‘ì—… ìµœì í™” ê°€ì´ë“œë¼ì¸

### âœ… ëª¨ë²” ì‚¬ë¡€ (Best Practices)

1. **ë°ì´í„° êµ¬ì¡° ì„¤ê³„**
   - ëª…í™•í•œ ì»¬ëŸ¼ ëª…ëª… ê·œì¹™ ì‚¬ìš©
   - ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ìœ ì§€
   - í•„ìˆ˜ í•„ë“œì™€ ì„ íƒ í•„ë“œ êµ¬ë¶„

2. **ì‹¤ì‹œê°„ í˜‘ì—…**
   - ë³€ê²½ ì‚¬í•­ ì¦‰ì‹œ ì»¤ë°‹
   - ì¶©ëŒ ë°œìƒì‹œ ì‹ ì†í•œ í•´ê²°
   - ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ í™œìš©

3. **í’ˆì§ˆ ê´€ë¦¬**
   - ì •ê¸°ì ì¸ ë°ì´í„° ê²€ì¦
   - ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì§€ì†

### âŒ í”¼í•´ì•¼ í•  ê²ƒë“¤ (Anti-Patterns)

1. **ë°ì´í„° ê´€ë¦¬**
   - ìˆ˜ë™ ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ê¸ˆì§€
   - ì¤‘ë³µ ë°ì´í„° ì†ŒìŠ¤ ìš´ì˜ ê¸ˆì§€
   - ê²€ì¦ ì—†ëŠ” í”„ë¡œë•ì…˜ ë°°í¬ ê¸ˆì§€

2. **í˜‘ì—… ë°©ì‹**
   - ì§ì ‘ì ì¸ DB ìˆ˜ì • ê¸ˆì§€
   - ì–¸ì–´ ì „ë¬¸ê°€ ê°„ ì§ì ‘ ì†Œí†µ ê¸ˆì§€
   - ì¼ë°©ì ì¸ ê¸°ìˆ  ê²°ì • ê¸ˆì§€

---

**ì´ ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ ê¸°íšìì˜ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë³€ê²½ì´ ìë™ìœ¼ë¡œ ê²Œì„ê³¼ ì‹œìŠ¤í…œ ì „ì²´ì— ë°˜ì˜ë˜ëŠ” ì™„ì „ ìë™í™”ëœ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**